{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-09 17:15:37,164] A new study created in memory with name: no-name-158f206e-3a4d-4bad-a7ac-a537985b4947\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:15:43,401] Trial 0 finished with value: 284.15348983289914 and parameters: {'model_type': 'elasticnet', 'alpha': 0.11102637572855162, 'l1_ratio': 0.1253897537140837}. Best is trial 0 with value: 284.15348983289914.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.219e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:15:46,714] Trial 1 finished with value: 271.86082591283906 and parameters: {'model_type': 'lasso', 'alpha': 0.10295482320782544}. Best is trial 1 with value: 271.86082591283906.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "[I 2024-11-09 17:15:47,236] Trial 2 finished with value: 340.58426750301214 and parameters: {'model_type': 'elasticnet', 'alpha': 0.9696328542064157, 'l1_ratio': 0.5003735093900242}. Best is trial 1 with value: 271.86082591283906.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.462e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:15:51,213] Trial 3 finished with value: 272.31567489248613 and parameters: {'model_type': 'lasso', 'alpha': 0.014039479699951334}. Best is trial 1 with value: 271.86082591283906.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.709e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:15:55,152] Trial 4 finished with value: 272.33734597339134 and parameters: {'model_type': 'lasso', 'alpha': 0.010209802025004572}. Best is trial 1 with value: 271.86082591283906.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.473e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:15:58,026] Trial 5 finished with value: 271.0488767876236 and parameters: {'model_type': 'lasso', 'alpha': 0.6262204727531051}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "[I 2024-11-09 17:15:59,575] Trial 6 finished with value: 293.4252322867897 and parameters: {'model_type': 'elasticnet', 'alpha': 0.5009191388696641, 'l1_ratio': 0.6769636553336531}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.145e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:16:04,283] Trial 7 finished with value: 271.9795659272829 and parameters: {'model_type': 'lasso', 'alpha': 0.06888995504643952}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.564e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:16:07,533] Trial 8 finished with value: 271.36506445101173 and parameters: {'model_type': 'lasso', 'alpha': 0.24080465695385048}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.067e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:16:11,567] Trial 9 finished with value: 271.90960960857336 and parameters: {'model_type': 'lasso', 'alpha': 0.08752045685823774}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
      "[I 2024-11-09 17:16:36,422] Trial 10 finished with value: 672.0631897885405 and parameters: {'model_type': 'svr', 'C': 5.608402865653786, 'epsilon': 0.25701560348026087}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
      "[I 2024-11-09 17:17:02,290] Trial 11 finished with value: 1103.4940051419587 and parameters: {'model_type': 'svr', 'C': 0.1112117808457033, 'epsilon': 0.016442157603406237}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:17:15,735] Trial 12 finished with value: 271.0821517377019 and parameters: {'model_type': 'lasso', 'alpha': 0.3612898858049434}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:17:19,888] Trial 13 finished with value: 271.060857681983 and parameters: {'model_type': 'lasso', 'alpha': 0.3809599540831527}. Best is trial 5 with value: 271.0488767876236.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:17:22,949] Trial 14 finished with value: 270.9978254562343 and parameters: {'model_type': 'lasso', 'alpha': 0.6639215697487388}. Best is trial 14 with value: 270.9978254562343.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
      "[I 2024-11-09 17:17:47,061] Trial 15 finished with value: 1079.2239021225207 and parameters: {'model_type': 'svr', 'C': 0.3344473250822739, 'epsilon': 0.46026872802877844}. Best is trial 14 with value: 270.9978254562343.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:17:49,532] Trial 16 finished with value: 270.64388614039984 and parameters: {'model_type': 'lasso', 'alpha': 0.952874755686311}. Best is trial 16 with value: 270.64388614039984.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:17:52,157] Trial 17 finished with value: 270.6287877313965 and parameters: {'model_type': 'lasso', 'alpha': 0.9658169357172061}. Best is trial 17 with value: 270.6287877313965.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:17:56,504] Trial 18 finished with value: 273.80784889961603 and parameters: {'model_type': 'elasticnet', 'alpha': 0.2151256340117479, 'l1_ratio': 0.8586981196975183}. Best is trial 17 with value: 270.6287877313965.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
      "[I 2024-11-09 17:18:20,067] Trial 19 finished with value: 551.6280190376124 and parameters: {'model_type': 'svr', 'C': 9.089687342332534, 'epsilon': 0.012918866828605706}. Best is trial 17 with value: 270.6287877313965.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.958e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:18:23,809] Trial 20 finished with value: 272.15732064669737 and parameters: {'model_type': 'lasso', 'alpha': 0.036468212487225676}. Best is trial 17 with value: 270.6287877313965.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:18:26,282] Trial 21 finished with value: 270.60453797521393 and parameters: {'model_type': 'lasso', 'alpha': 0.985804957096115}. Best is trial 21 with value: 270.60453797521393.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:18:29,687] Trial 22 finished with value: 270.64503884176355 and parameters: {'model_type': 'lasso', 'alpha': 0.9519032742489926}. Best is trial 21 with value: 270.60453797521393.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:18:32,477] Trial 23 finished with value: 270.6043993208503 and parameters: {'model_type': 'lasso', 'alpha': 0.9859186305153261}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:18:40,052] Trial 24 finished with value: 271.3817233415549 and parameters: {'model_type': 'lasso', 'alpha': 0.23572664919174283}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.150e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:18:52,039] Trial 25 finished with value: 271.1538984134727 and parameters: {'model_type': 'lasso', 'alpha': 0.5496379539765751}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:19:02,817] Trial 26 finished with value: 271.08306522183136 and parameters: {'model_type': 'lasso', 'alpha': 0.3608349797066861}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:19:12,965] Trial 27 finished with value: 270.9517338454397 and parameters: {'model_type': 'lasso', 'alpha': 0.6993915353746352}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "[I 2024-11-09 17:19:37,129] Trial 28 finished with value: 290.7559029513934 and parameters: {'model_type': 'elasticnet', 'alpha': 0.16868346154021865, 'l1_ratio': 0.14997935982021882}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
      "[I 2024-11-09 17:20:21,388] Trial 29 finished with value: 1024.1245492735147 and parameters: {'model_type': 'svr', 'C': 0.857346563592991, 'epsilon': 0.07256578694779078}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "[I 2024-11-09 17:20:22,255] Trial 30 finished with value: 308.02442417471764 and parameters: {'model_type': 'elasticnet', 'alpha': 0.42293751249477346, 'l1_ratio': 0.3792297232489348}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:20:30,252] Trial 31 finished with value: 270.6505181052073 and parameters: {'model_type': 'lasso', 'alpha': 0.9471887611370924}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:20:33,417] Trial 32 finished with value: 270.89713262605704 and parameters: {'model_type': 'lasso', 'alpha': 0.7432274837971028}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:20:36,995] Trial 33 finished with value: 270.6774352596301 and parameters: {'model_type': 'lasso', 'alpha': 0.9240619863396855}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.912e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:20:39,787] Trial 34 finished with value: 271.1239492179392 and parameters: {'model_type': 'lasso', 'alpha': 0.5712615078630292}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.655e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:20:43,061] Trial 35 finished with value: 272.1207632439185 and parameters: {'model_type': 'lasso', 'alpha': 0.041605792155422386}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:20:46,206] Trial 36 finished with value: 271.21473018332546 and parameters: {'model_type': 'lasso', 'alpha': 0.30342429075937954}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.258e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:20:49,590] Trial 37 finished with value: 271.699346205366 and parameters: {'model_type': 'lasso', 'alpha': 0.15102370712408805}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "[I 2024-11-09 17:20:50,246] Trial 38 finished with value: 337.218241907629 and parameters: {'model_type': 'elasticnet', 'alpha': 0.768201874517388, 'l1_ratio': 0.3990354337771668}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.233e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:20:53,503] Trial 39 finished with value: 271.1579920613404 and parameters: {'model_type': 'lasso', 'alpha': 0.49880820532459824}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:20:56,906] Trial 40 finished with value: 270.83895246734045 and parameters: {'model_type': 'lasso', 'alpha': 0.7913728622220383}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:21:00,183] Trial 41 finished with value: 270.70297371449925 and parameters: {'model_type': 'lasso', 'alpha': 0.9020547665209816}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:21:07,572] Trial 42 finished with value: 270.6908614130525 and parameters: {'model_type': 'lasso', 'alpha': 0.9124980244702525}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:21:09,842] Trial 43 finished with value: 270.60814176773226 and parameters: {'model_type': 'lasso', 'alpha': 0.9828411031665155}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.066e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:21:22,772] Trial 44 finished with value: 271.14768862742875 and parameters: {'model_type': 'lasso', 'alpha': 0.4847079562407162}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.396e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:21:28,476] Trial 45 finished with value: 271.0318972826773 and parameters: {'model_type': 'lasso', 'alpha': 0.6384945047981416}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "[I 2024-11-09 17:21:31,795] Trial 46 finished with value: 270.9860088128425 and parameters: {'model_type': 'lasso', 'alpha': 0.6730360132418729}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
      "[I 2024-11-09 17:22:10,092] Trial 47 finished with value: 899.1621331758415 and parameters: {'model_type': 'svr', 'C': 2.1774562302265235, 'epsilon': 0.0688506636277808}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.975e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:22:26,805] Trial 48 finished with value: 272.2586593215409 and parameters: {'model_type': 'lasso', 'alpha': 0.0214647924718062}. Best is trial 23 with value: 270.6043993208503.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17272\\179164391.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.261e+06, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:22:46,085] Trial 49 finished with value: 273.92297372708214 and parameters: {'model_type': 'elasticnet', 'alpha': 0.30184944654885654, 'l1_ratio': 0.8954306989356203}. Best is trial 23 with value: 270.6043993208503.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+06, tolerance: 2.786e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "INFO:__main__:Final model retrained on the entire training dataset.\n",
      "INFO:__main__:Test dataset prepared.\n",
      "INFO:__main__:Predictions made on the test set.\n",
      "INFO:__main__:Submission file saved as 'submission_advanced_regression.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop(columns=['id', 'yield'])\n",
    "y = train_data['yield']\n",
    "X_test = test_data.drop(columns=['id'])\n",
    "\n",
    "# Define Optuna objective function with selected models\n",
    "def objective(trial):\n",
    "    model_type = trial.suggest_categorical('model_type', ['lasso', 'elasticnet', 'svr'])\n",
    "    \n",
    "    if model_type == 'lasso':\n",
    "        alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
    "        model = Lasso(alpha=alpha, max_iter=1000)\n",
    "    elif model_type == 'elasticnet':\n",
    "        alpha = trial.suggest_loguniform('alpha', 1e-2, 1.0)\n",
    "        l1_ratio = trial.suggest_uniform('l1_ratio', 0.1, 0.9)\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=1000)\n",
    "    elif model_type == 'svr':\n",
    "        C = trial.suggest_loguniform('C', 0.1, 10.0)\n",
    "        epsilon = trial.suggest_loguniform('epsilon', 0.01, 0.5)\n",
    "        model = SVR(C=C, epsilon=epsilon)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly_features', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, preds)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Optimize model using Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Retrieve the best parameters and model\n",
    "best_params = study.best_params\n",
    "model_type = best_params.pop('model_type')\n",
    "\n",
    "if model_type == 'lasso':\n",
    "    final_model = Lasso(**best_params, max_iter=1000)\n",
    "elif model_type == 'elasticnet':\n",
    "    final_model = ElasticNet(**best_params, max_iter=1000)\n",
    "elif model_type == 'svr':\n",
    "    final_model = SVR(**best_params)\n",
    "\n",
    "# Define final pipeline with best model\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly_features', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    ('model', final_model)\n",
    "])\n",
    "\n",
    "# Fit the final model pipeline on the entire training data\n",
    "final_pipeline.fit(X, y)\n",
    "logger.info(\"Final model retrained on the entire training dataset.\")\n",
    "\n",
    "# Prepare test data and make predictions\n",
    "logger.info(\"Test dataset prepared.\")\n",
    "y_test_pred = final_pipeline.predict(X_test)\n",
    "logger.info(\"Predictions made on the test set.\")\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'yield': y_test_pred\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission_advanced_regression.csv', index=False)\n",
    "logger.info(\"Submission file saved as 'submission_advanced_regression.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-09 17:29:47,601] A new study created in memory with name: no-name-63b37b0f-3bc0-457c-a5db-ef9dc8f837bf\n",
      "[I 2024-11-09 17:31:00,122] Trial 0 finished with value: 1105.8660131143704 and parameters: {'model_type': 'svr', 'C': 1.2566215325686747, 'epsilon': 0.18190381056131827}. Best is trial 0 with value: 1105.8660131143704.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.793e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:31:15,423] Trial 1 finished with value: 269.98723839335753 and parameters: {'model_type': 'lasso', 'alpha': 0.07579873707856588}. Best is trial 1 with value: 269.98723839335753.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+09, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:31:29,388] Trial 2 finished with value: 270.3727172600074 and parameters: {'model_type': 'elasticnet', 'alpha': 0.029771213962028434, 'l1_ratio': 0.47490683621639107}. Best is trial 1 with value: 269.98723839335753.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:31:50,041] Trial 3 finished with value: 269.5257397623815 and parameters: {'model_type': 'elasticnet', 'alpha': 0.03558749665667616, 'l1_ratio': 0.7320253129101897}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.814e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:32:30,188] Trial 4 finished with value: 270.0933489018264 and parameters: {'model_type': 'lasso', 'alpha': 0.028109645969141492}. Best is trial 3 with value: 269.5257397623815.\n",
      "[I 2024-11-09 17:33:43,089] Trial 5 finished with value: 1087.526254882847 and parameters: {'model_type': 'svr', 'C': 3.6366341472900974, 'epsilon': 0.11240070873589827}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.818e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:34:07,518] Trial 6 finished with value: 270.09357365424904 and parameters: {'model_type': 'lasso', 'alpha': 0.028072009518308863}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+09, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:34:22,950] Trial 7 finished with value: 272.85467244486017 and parameters: {'model_type': 'elasticnet', 'alpha': 0.07942238339092782, 'l1_ratio': 0.6072718607829997}. Best is trial 3 with value: 269.5257397623815.\n",
      "[I 2024-11-09 17:35:42,725] Trial 8 finished with value: 1104.4403779261438 and parameters: {'model_type': 'svr', 'C': 1.4405532103465117, 'epsilon': 0.09873399335104968}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.843e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:36:13,050] Trial 9 finished with value: 269.91801306763256 and parameters: {'model_type': 'lasso', 'alpha': 0.09695660255575639}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:36:35,652] Trial 10 finished with value: 269.8581682357628 and parameters: {'model_type': 'elasticnet', 'alpha': 0.05307685238529204, 'l1_ratio': 0.7758946322278608}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.565e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:36:52,600] Trial 11 finished with value: 269.7098400464761 and parameters: {'model_type': 'elasticnet', 'alpha': 0.05355198324544202, 'l1_ratio': 0.7972241815660646}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:37:21,810] Trial 12 finished with value: 269.6589563856743 and parameters: {'model_type': 'elasticnet', 'alpha': 0.05238352709410152, 'l1_ratio': 0.799274295099942}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:38:16,229] Trial 13 finished with value: 270.23811436354526 and parameters: {'model_type': 'elasticnet', 'alpha': 0.045334744881373235, 'l1_ratio': 0.6755972476631977}. Best is trial 3 with value: 269.5257397623815.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.634e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:38:55,278] Trial 14 finished with value: 269.43141575191675 and parameters: {'model_type': 'elasticnet', 'alpha': 0.010470894061708633, 'l1_ratio': 0.331074814132619}. Best is trial 14 with value: 269.43141575191675.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.632e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-11-09 17:39:52,814] Trial 15 finished with value: 269.432157971176 and parameters: {'model_type': 'elasticnet', 'alpha': 0.01080271407495652, 'l1_ratio': 0.3447534219963484}. Best is trial 14 with value: 269.43141575191675.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop(columns=['id', 'yield'])\n",
    "y = train_data['yield']\n",
    "X_test = test_data.drop(columns=['id'])\n",
    "\n",
    "# Feature Engineering: Selecting specific interaction terms for key features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X[['clonesize', 'honeybee', 'bumbles', 'fruitmass']])\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out())\n",
    "X = pd.concat([X, X_poly_df], axis=1)\n",
    "\n",
    "# Define Optuna objective function with advanced tuning\n",
    "def objective(trial):\n",
    "    model_type = trial.suggest_categorical('model_type', ['lasso', 'elasticnet', 'svr'])\n",
    "    \n",
    "    if model_type == 'lasso':\n",
    "        alpha = trial.suggest_float('alpha', 0.01, 0.1)\n",
    "        model = Lasso(alpha=alpha, max_iter=1000)\n",
    "    elif model_type == 'elasticnet':\n",
    "        alpha = trial.suggest_float('alpha', 0.01, 0.1)\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0.3, 0.8)\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=1000)\n",
    "    elif model_type == 'svr':\n",
    "        C = trial.suggest_float('C', 0.5, 5.0)\n",
    "        epsilon = trial.suggest_float('epsilon', 0.05, 0.2)\n",
    "        model = SVR(C=C, epsilon=epsilon)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly_features', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, preds)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Optimize model using Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)  # Reduced trials for faster computation\n",
    "\n",
    "# Retrieve the best parameters and model\n",
    "best_params = study.best_params\n",
    "model_type = best_params.pop('model_type')\n",
    "\n",
    "if model_type == 'lasso':\n",
    "    final_model = Lasso(**best_params, max_iter=1000)\n",
    "elif model_type == 'elasticnet':\n",
    "    final_model = ElasticNet(**best_params, max_iter=1000)\n",
    "elif model_type == 'svr':\n",
    "    final_model = SVR(**best_params)\n",
    "\n",
    "# Define final pipeline with best model and selective polynomial features\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly_features', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    ('model', final_model)\n",
    "])\n",
    "\n",
    "# Fit the final model pipeline on the entire training data\n",
    "final_pipeline.fit(X, y)\n",
    "logger.info(\"Final model retrained on the entire training dataset.\")\n",
    "\n",
    "# Prepare test data and make predictions\n",
    "X_test_poly = poly.transform(X_test[['clonesize', 'honeybee', 'bumbles', 'fruitmass']])\n",
    "X_test_poly_df = pd.DataFrame(X_test_poly, columns=poly.get_feature_names_out())\n",
    "X_test = pd.concat([X_test, X_test_poly_df], axis=1)\n",
    "y_test_pred = final_pipeline.predict(X_test)\n",
    "logger.info(\"Predictions made on the test set.\")\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'yield': y_test_pred\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission_advanced_regression11.csv', index=False)\n",
    "logger.info(\"Submission file saved as 'submission_advanced_regression11.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
